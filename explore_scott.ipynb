{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7b9d0e6c-493f-4d0a-a1d5-3e9003dfdcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import wrangle_scott\n",
    "import scipy.stats as stats\n",
    "import functions\n",
    "#splits, scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe72603-54d0-4c1a-ae70-5ff003098c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1221925d-6c14-4c16-8a78-e74707aaf179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1439a05-5c0b-49eb-9443-5e09b6ebe341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2e2784c-20db-48de-bf7e-56b0003eff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(seed=123):\n",
    "    '''\n",
    "    Create a list of machine learning models.\n",
    "            Parameters:\n",
    "                    seed (integer): random seed of the models\n",
    "            Returns:\n",
    "                    models (list): list containing the models\n",
    "    This includes best fit hyperparamaenters                \n",
    "    '''\n",
    "    models = []\n",
    "    models.append(('k_nearest_neighbors', KNeighborsClassifier(n_neighbors=100)))\n",
    "    models.append(('logistic_regression', LogisticRegression(random_state=seed)))\n",
    "    models.append(('DecisionTreeClassifier', DecisionTreeClassifier(max_depth=3,min_samples_split=4,random_state=seed)))\n",
    "    models.append(('random_forest', RandomForestClassifier(max_depth=3,random_state=seed)))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "007f75af-b415-4c76-b12f-7c1aa05b21a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    # create models list\n",
    "    models = create_models(seed=123)\n",
    "    X_train, y_train, X_validate, y_validate, X_test, y_test = get_xy()\n",
    "    # initialize results dataframe\n",
    "    results = pd.DataFrame(columns=['model', 'set', 'accuracy', 'recall'])\n",
    "    \n",
    "    # loop through models and fit/predict on train and validate sets\n",
    "    for name, model in models:\n",
    "        # fit the model with the training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # make predictions with the training data\n",
    "        train_predictions = model.predict(X_train)\n",
    "        \n",
    "        # calculate training accuracy and recall\n",
    "        train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "        train_recall = recall_score(y_train, train_predictions)\n",
    "        \n",
    "        # make predictions with the validation data\n",
    "        val_predictions = model.predict(X_validate)\n",
    "        \n",
    "        # calculate validation accuracy and recall\n",
    "        val_accuracy = accuracy_score(y_validate, val_predictions)\n",
    "        val_recall = recall_score(y_validate, val_predictions)\n",
    "        \n",
    "        # append results to dataframe\n",
    "        results = results.append({'model': name, 'set': 'train', 'accuracy': train_accuracy, 'recall': train_recall}, ignore_index=True)\n",
    "        results = results.append({'model': name, 'set': 'validate', 'accuracy': val_accuracy, 'recall': val_recall}, ignore_index=True)\n",
    "        '''\n",
    "        this section left in case I want to return to printed format rather than data frame\n",
    "        # print classifier accuracy and recall\n",
    "        print('Classifier: {}, Train Accuracy: {}, Train Recall: {}, Validation Accuracy: {}, Validation Recall: {}'.format(name, train_accuracy, train_recall, val_accuracy, val_recall))\n",
    "        '''\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d2e61-f22f-4afd-a535-1210ce3a71a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_github_repositories(language):\n",
    "    headers = {\n",
    "        'Authorization': 'Bearer YOUR_PERSONAL_ACCESS_TOKEN'\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'q': f'language:{language}',\n",
    "        'per_page': 100,  # Adjust the number of repositories per page as needed\n",
    "        'sort': 'stars'  # You can sort by different criteria like stars, forks, etc.\n",
    "    }\n",
    "\n",
    "    response = requests.get('https://api.github.com/search/repositories', headers=headers, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    if 'items' in data:\n",
    "        repositories = data['items']\n",
    "        return repositories\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Example usage:\n",
    "python_repositories = get_github_repositories('python')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
